{"cells":[{"cell_type":"markdown","id":"3a564d5f","metadata":{"id":"3a564d5f"},"source":["#  Классификация текстов с использованием эмбеддингов слов.\n","\n","__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n","\n","Материалы:\n","* Deep Learning with PyTorch (2020) Авторы: Eli Stevens, Luca Antiga, Thomas Viehmann\n","* https://pytorch.org/text/stable/vocab.html\n","* https://pytorch.org/text/stable/transforms.html\n","* https://rusvectores.org/\n","* https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n","* https://github.com/natasha/navec\n","* https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n","* https://torchmetrics.readthedocs.io/en/stable/"]},{"cell_type":"markdown","id":"c9ecd663","metadata":{"id":"c9ecd663"},"source":["## Задачи для совместного разбора"]},{"cell_type":"markdown","id":"a52a9103","metadata":{"id":"a52a9103"},"source":["1\\. Реализуйте модель для классификации текстов с использованием слоя `nn.Embedding`. Заморозьте веса слоя эмбеддингов."]},{"cell_type":"code","source":["import torch as th\n","import torch.nn as nn"],"metadata":{"id":"I_8QShM5rnlK"},"id":"I_8QShM5rnlK","execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = th.randint(0, 1000, size=(16, 20)).long()\n","y = th.LongTensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])"],"metadata":{"id":"Jg6yw88Drnvi"},"id":"Jg6yw88Drnvi","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Net(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.emb = nn.Embedding(\n","        num_embeddings=1000,\n","        embedding_dim=100,\n","    )\n","    self.fc = nn.Linear(in_features=100, out_features=2)\n","\n","  def forward(self, X):\n","    # X: batch_size x seq_len\n","    e = self.emb(X) # batch_size x seq_len x emb_dim\n","    # преобразовать эмб. токенов в эмб. последовательности\n","    e = e.mean(dim=1) # batch_size x emb_dim\n","    out = self.fc(e) # batch_size x 2\n","    return out"],"metadata":{"id":"njizOyrBr9ba"},"id":"njizOyrBr9ba","execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Net()\n","y_pred = model(X)\n","y_pred.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WqaPyXsvs4SS","executionInfo":{"status":"ok","timestamp":1698218373797,"user_tz":-180,"elapsed":367,"user":{"displayName":"Никита Блохин","userId":"16402972581398673009"}},"outputId":"a42f0a20-f160-4ef6-8f40-538e35af3335"},"id":"WqaPyXsvs4SS","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([16, 2])"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["model.emb.weight.requires_grad_(False)\n","model.emb.weight.requires_grad"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OpirVyRVtLcB","executionInfo":{"status":"ok","timestamp":1698218453660,"user_tz":-180,"elapsed":7,"user":{"displayName":"Никита Блохин","userId":"16402972581398673009"}},"outputId":"5dd58b60-99d7-4b2e-c7e3-8466d272fb60"},"id":"OpirVyRVtLcB","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","id":"7326c769","metadata":{"id":"7326c769"},"source":["2\\. Используя `torchmetrics`, рассчитайте значение accuracy по эпохам с использованием мини-пакетного градиентого спуска."]},{"cell_type":"code","source":["!pip install torchmetrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6RwgBxR5xBTk","executionInfo":{"status":"ok","timestamp":1698219443354,"user_tz":-180,"elapsed":8993,"user":{"displayName":"Никита Блохин","userId":"16402972581398673009"}},"outputId":"4b5245d4-2984-4d14-f801-7651748be855"},"id":"6RwgBxR5xBTk","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchmetrics\n","  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n","Installing collected packages: lightning-utilities, torchmetrics\n","Successfully installed lightning-utilities-0.9.0 torchmetrics-1.2.0\n"]}]},{"cell_type":"code","source":["import torchmetrics as M"],"metadata":{"id":"Tc4DnP-Cw-bZ"},"id":"Tc4DnP-Cw-bZ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","dset = TensorDataset(X, y)\n","loader = DataLoader(dset, batch_size=4)\n","\n","n_epochs = 5\n","lr = 0.001\n","\n","model = Net()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","for epoch in range(n_epochs):\n","  preds, trues = [], []\n","  running_correct, running_count = 0, 0\n","  running_acc, running_steps = 0, 0\n","\n","  acc_m = M.Accuracy(task=\"binary\")\n","\n","  for step, (X_b, y_b) in enumerate(loader):\n","    y_pred = model(X_b) # batch_size x n_classes\n","    loss = criterion(y_pred, y_b)\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","    # v1\n","    preds.extend(list(y_pred.argmax(dim=1)))\n","    trues.extend(list(y_b))\n","\n","    # v2\n","    running_correct += (y_pred.argmax(dim=1) == y_b).sum()\n","    running_count += len(y_b)\n","\n","    # v3\n","    acc = (y_pred.argmax(dim=1) == y_b).float().mean()\n","    running_acc += acc\n","    running_steps += 1\n","\n","    # v4\n","    acc_m.update(y_pred.argmax(dim=1), y_b)\n","\n","    print(f\"{epoch=} {step=} {acc.item()=}\")\n","\n","  preds = th.tensor(preds)\n","  trues = th.tensor(trues)\n","  acc_epochs = (preds == trues).float().mean()\n","  acc_epochs2 = running_correct / running_count\n","  acc_epochs3 = running_acc / running_steps\n","  acc_epochs4 = acc_m.compute()\n","  print(f\"{epoch=} \"\n","        f\"{acc_epochs.item()=} \\n\"\n","        f\"{acc_epochs2.item()=} \\n\"\n","        f\"{acc_epochs3.item()=} \\n\"\n","        f\"{acc_epochs4.item()=}\"\n","  )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GnjJZ7rst4Iy","executionInfo":{"status":"ok","timestamp":1698219669241,"user_tz":-180,"elapsed":412,"user":{"displayName":"Никита Блохин","userId":"16402972581398673009"}},"outputId":"29e2eb92-fb2b-4fff-bcef-c751bad902eb"},"id":"GnjJZ7rst4Iy","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch=0 step=0 acc.item()=0.25\n","epoch=0 step=1 acc.item()=0.5\n","epoch=0 step=2 acc.item()=0.5\n","epoch=0 step=3 acc.item()=0.5\n","epoch=0 acc_epochs.item()=0.4375 \n","acc_epochs2.item()=0.4375  \n","acc_epochs3.item()=0.4375  \n","acc_epochs4.item()=0.4375\n","epoch=1 step=0 acc.item()=0.5\n","epoch=1 step=1 acc.item()=0.5\n","epoch=1 step=2 acc.item()=0.5\n","epoch=1 step=3 acc.item()=0.5\n","epoch=1 acc_epochs.item()=0.5 \n","acc_epochs2.item()=0.5  \n","acc_epochs3.item()=0.5  \n","acc_epochs4.item()=0.5\n","epoch=2 step=0 acc.item()=0.5\n","epoch=2 step=1 acc.item()=0.75\n","epoch=2 step=2 acc.item()=0.5\n","epoch=2 step=3 acc.item()=0.5\n","epoch=2 acc_epochs.item()=0.5625 \n","acc_epochs2.item()=0.5625  \n","acc_epochs3.item()=0.5625  \n","acc_epochs4.item()=0.5625\n","epoch=3 step=0 acc.item()=0.5\n","epoch=3 step=1 acc.item()=0.75\n","epoch=3 step=2 acc.item()=0.5\n","epoch=3 step=3 acc.item()=0.5\n","epoch=3 acc_epochs.item()=0.5625 \n","acc_epochs2.item()=0.5625  \n","acc_epochs3.item()=0.5625  \n","acc_epochs4.item()=0.5625\n","epoch=4 step=0 acc.item()=0.5\n","epoch=4 step=1 acc.item()=0.75\n","epoch=4 step=2 acc.item()=0.75\n","epoch=4 step=3 acc.item()=0.5\n","epoch=4 acc_epochs.item()=0.625 \n","acc_epochs2.item()=0.625  \n","acc_epochs3.item()=0.625  \n","acc_epochs4.item()=0.625\n"]}]},{"cell_type":"markdown","id":"4d7b6d63","metadata":{"id":"4d7b6d63"},"source":["## Задачи для самостоятельного решения"]},{"cell_type":"markdown","id":"9cf9cbb5","metadata":{"id":"9cf9cbb5"},"source":["<p class=\"task\" id=\"1\"></p>\n","\n","1\\. Считайте файл `lenta_news.csv` и разбейте на обучающую и тестовую выборку. Выполните предобработку текста и создайте Vocab на основе обучающей выборки (токен - слово). Выведите на экран количество токенов в полученном словаре.\n","\n","- [ ] Проверено на семинаре"]},{"cell_type":"markdown","id":"0cb3a54b","metadata":{"id":"0cb3a54b"},"source":["<p class=\"task\" id=\"2\"></p>\n","\n","\n","2\\. Создайте класс `NewsDataset`. Реализуйте метод `__getitem__` таким образом, чтобы он возвращал набор индексов токенов для текста новости (или новостей, если используются срезы) и метки классов для этих новостей. Используя преобразования, сделайте длины наборов индексов одинаковой фиксированной длины (подходящее значение определите сами). Закодируйте целыми числами категории новостей. Создайте два объекта класса `NewsDataset` (для обучающей и тестовой выборки).\n","\n","Выведите на экран результат выполнения `train_dataset[0]` и `train_dataset[:3]`\n","\n","- [ ] Проверено на семинаре"]},{"cell_type":"markdown","id":"5c5e54aa","metadata":{"id":"5c5e54aa"},"source":["<p class=\"task\" id=\"3\"></p>\n","\n","3\\. Реализуйте модель, которая получает на вход батч новостей (в виде индексов токенов), пропускает его через слой `nn.Embedding` (матрица эмбеддингов инициализируется случайным образом), после чего передает полученные эмбеддинги части-классификатору (который состоит из некоторого количества полносвязных слоев). Для получения эмбеддинга для предложения на основе эмбеддингов слов воспользуйтесь любой функцией агрегации, сохраняющей размерности векторов (сумма, усреднение и т.д.).\n","\n","Решите задачу классификации новостей. Постройте график изменения значения функции потерь на обучающем множестве в зависимости от номера эпохи, графики изменения метрики f1 на обучающем и тестовом множестве в зависимости от эпохи. Выведите на экран отчет по классификации на обучающем и тестовом множестве.\n","\n","- [ ] Проверено на семинаре"]},{"cell_type":"markdown","id":"da94b053","metadata":{"id":"da94b053"},"source":["<p class=\"task\" id=\"4\"></p>\n","\n","4\\. Повторите решение задачи 3, создав слой `nn.Embedding` на основе предобученных векторов для слов русского языка и заморозив веса данного слоя. Для поиска векторов можете воспользоваться любым известным вам ресурсом. Сравните качество полученного решения и решения из предыдущей задачи, а также время, затраченное на обучения моделей.  \n","\n","- [ ] Проверено на семинаре"]},{"cell_type":"markdown","id":"c5690545","metadata":{"id":"c5690545"},"source":["<p class=\"task\" id=\"5\"></p>\n","\n","5\\. Повторите решение задачи 3, не замораживая веса слоя эмбеддингов. Сравните качество полученного решения и решений из предыдущих задач, а также время, затраченное на обучения моделей.  \n","\n","- [ ] Проверено на семинаре"]},{"cell_type":"markdown","id":"1408f13a","metadata":{"id":"1408f13a"},"source":["<p class=\"task\" id=\"6\"></p>\n","\n","6\\. Воспользовавшись обученной моделью из предыдущей задачи, визуализируйте эмбеддинги новостей из тестовой выборки в двумерном пространстве. Для проекции точек в двумерное пространство воспользуйтесь алгоритмом t-SNE. Раскрасьте точки в цвет, соответствующий классу новости.\n","\n","- [ ] Проверено на семинаре"]},{"cell_type":"markdown","id":"66caa919","metadata":{"id":"66caa919"},"source":["## Обратная связь\n","- [ ] Хочу получить обратную связь по решению"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[{"file_id":"1drqv3BZycOFrnXztY6aGHdUazxdUg40A","timestamp":1698319601412}]}},"nbformat":4,"nbformat_minor":5}