{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a564d5f",
   "metadata": {},
   "source": [
    "#  Загрузка предобученных эмбеддингов\n",
    "\n",
    "__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n",
    "\n",
    "Материалы: \n",
    "* Deep Learning with PyTorch (2020) Авторы: Eli Stevens, Luca Antiga, Thomas Viehmann \n",
    "* https://rusvectores.org/\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "* https://github.com/natasha/navec\n",
    "* https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ecd663",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bae349",
   "metadata": {},
   "source": [
    "1\\. Создайте объект `nn.Embedding` на основе файла `ruscorpora_upos_skipgram_300_5_2018_sample.vec`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7b6d63",
   "metadata": {},
   "source": [
    "## Задачи для самостоятельного решения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5cc3cc",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"1\"></p>\n",
    "\n",
    "1\\. Воспользовавшись предобученными эмбеддингами [ruscorpora_upos_skipgram_300_5_2018](https://rusvectores.org/static/models/rusvectores4/RNC/ruscorpora_upos_skipgram_300_5_2018.vec.gz), создайте словарь, где ключом является кортеж из слова и части речи, а значением - номер этого слова в файле эмбеддингами (первую строку при расчете номера строк не учитывайте). Выведите на экран количество элементов в словаре. Создайте двумерный массив эмбеддингов и выведите на экран его форму.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed305824",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"2\"></p>\n",
    "\n",
    "2\\. Используя PCA, уменьшите размерность загруженных эмбеддингов до 2. Визуализируйте на плоскости точки для слов \"кот\", \"кошка\", \"собака\", \"киса\", \"овчарка\", \"студент\", \"препод\". Добавьте для точек подписи.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea1d063",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"3\"></p>\n",
    "\n",
    "3\\. Напишите функцию, которая для заданного слова `word` находит `k` ближайших слов в смысле евклидова расстояния между эмбеддингами. Продемонстрируйте работу функции на словах из предыдущего задания.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084cf35c",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"4\"></p>\n",
    "\n",
    "4\\. Создайте слой `nn.Embedding` на основе загруженных эмбеддингов. Для каждого слова из задания 2 найдите соотетствующий ему индекс. Используя найденные индексы, получите для каждого слова его векторное представление. Выведите форму полученного тензора. \n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68543255",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"5\"></p>\n",
    "\n",
    "5\\. Создайте новый вариант `nn.Embedding`, где для нулевого индекса возвращается тензор из нулей, а для первого индекса возвращается тензор из чисел $\\frac{1}{300}$. Выведите на экран размер количество эмбеддингов и эмбеддинги для индексов 0 и 1.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f895720c",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"6\"></p>\n",
    "\n",
    "6\\. Для каждого слова в каждом предложении батча получите его индекс. При поиске индекса слова приводите слово к нормальной форме. Части речи для простоты можно не учитывать. В случае отсутствия слова в словаре используйте индекс 1. Дополните все наборы индексов до одного размера индексом 0. Используя найденные индексы, получите для каждого слова в каждом предложении его векторное представление. Выведите форму полученного тензора. \n",
    "\n",
    "Получите векторное представление каждого предложения путем усреднения эмбеддингов слов этого предложения. Выведите форму результата на экран.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2a6cf588",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\n",
    "    \"робот пылесос только что опередил меня и сожрал попкорнину которую я хотел поднять\",\n",
    "    \"я приходил к хирургу он мне предложил отрезать ухо\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf1a60c",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"7\"></p>\n",
    "\n",
    "7\\. Загрузите модель [navec_hudlit_v1_12B_500K_300d_100q.tar](https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar) с помощью пакета `navec`. Для каждого слова в каждом предложении батча получите его индекс. При поиске индекса слова приводите слово к нормальной форме. В случае отсутствия слова в словаре используйте индекс токена `<unk>`. Дополните все наборы индексов до одного размера индексом токена `<pad>`. Используя найденные индексы, получите для каждого слова в каждом предложении его векторное представление.  Выведите форму полученного тензора. \n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff2290",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\n",
    "    \"робот пылесос только что опередил меня и сожрал попкорнину которую я хотел поднять\",\n",
    "    \"я приходил к хирургу он мне предложил отрезать ухо\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66caa919",
   "metadata": {},
   "source": [
    "## Обратная связь\n",
    "- [ ] Хочу получить обратную связь по решению"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
