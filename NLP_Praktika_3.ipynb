{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60fae336-1ad0-47b2-9c92-738b6faa9547",
   "metadata": {},
   "source": [
    "Задание 3. Сравнить качество обучения классических методов машинного обучения и методов глубокого обучения на примере задачи классификации текстов. Сделать выводы.\n",
    "\n",
    "Датасет:\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "\n",
    "Темы: alt.atheism, misc.forsale, soc.religion.christian, talk.politics.mideast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48bf4a18-5b55-4367-a61b-00b1be273975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8b9fe08-1c25-4e97-beec-8a92fee8ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'misc.forsale', 'soc.religion.christian', 'talk.politics.mideast']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13107153-d15d-4c90-bcf4-18ee75a47678",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(newsgroups_train.data)\n",
    "X_test = vectorizer.transform(newsgroups_test.data)\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba8be20-a47c-437d-a546-a4ac239c72a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наивный Байесовский классификатор:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       319\n",
      "           1       0.98      0.98      0.98       390\n",
      "           2       0.91      0.97      0.94       398\n",
      "           3       0.98      0.92      0.95       376\n",
      "\n",
      "    accuracy                           0.95      1483\n",
      "   macro avg       0.95      0.94      0.94      1483\n",
      "weighted avg       0.95      0.95      0.95      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "nb_pred = nb_classifier.predict(X_test)\n",
    "print(\"Наивный Байесовский классификатор:\\n\", classification_report(y_test, nb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2977b38-3c76-4725-a180-cb4311dbc2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86       319\n",
      "           1       0.95      0.99      0.97       390\n",
      "           2       0.88      0.97      0.92       398\n",
      "           3       0.97      0.88      0.92       376\n",
      "\n",
      "    accuracy                           0.92      1483\n",
      "   macro avg       0.92      0.92      0.92      1483\n",
      "weighted avg       0.92      0.92      0.92      1483\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qtr/anaconda3/envs/rapids-23.12/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "lr_pred = lr_classifier.predict(X_test)\n",
    "print(\"Логистическая регрессия:\\n\", classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d2f1e2-1bea-44c7-bbb6-1224a0990b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Линейная регрессия:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -8       0.00      0.00      0.00         0\n",
      "          -4       0.00      0.00      0.00         0\n",
      "          -2       0.00      0.00      0.00         0\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           0       0.80      0.38      0.51       319\n",
      "           1       0.56      0.81      0.66       390\n",
      "           2       0.55      0.69      0.61       398\n",
      "           3       0.70      0.34      0.46       376\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.57      1483\n",
      "   macro avg       0.19      0.16      0.16      1483\n",
      "weighted avg       0.65      0.57      0.57      1483\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qtr/anaconda3/envs/rapids-23.12/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/qtr/anaconda3/envs/rapids-23.12/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/qtr/anaconda3/envs/rapids-23.12/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "linreg_classifier = LinearRegression()\n",
    "linreg_classifier.fit(X_train, y_train)\n",
    "linreg_pred = np.rint(linreg_classifier.predict(X_test)).astype(int)\n",
    "print(\"Линейная регрессия:\\n\", classification_report(y_test, linreg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdc35ba4-9e37-4a23-91c5-119648d57361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.60      0.69       319\n",
      "           1       0.71      0.96      0.81       390\n",
      "           2       0.77      0.80      0.78       398\n",
      "           3       0.88      0.72      0.79       376\n",
      "\n",
      "    accuracy                           0.78      1483\n",
      "   macro avg       0.79      0.77      0.77      1483\n",
      "weighted avg       0.79      0.78      0.77      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "svm_pred = svm_classifier.predict(X_test)\n",
    "print(\"SVM:\\n\", classification_report(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df76b856-c0a9-4844-9512-2f804818d359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38ded9a8-a9fc-48a9-9375-67f60fc04823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68dc7ae7-027f-44e6-8436-f331c2b2e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'misc.forsale', 'soc.religion.christian', 'talk.politics.mideast']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f484454-35a8-48fe-b67f-7e13655624b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer() \n",
    "X_train = vectorizer.fit_transform(newsgroups_train.data).toarray()\n",
    "X_test = vectorizer.transform(newsgroups_test.data).toarray()\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train).float()\n",
    "X_test_tensor = torch.tensor(X_test).float()\n",
    "y_train_tensor = torch.tensor(y_train).long()\n",
    "y_test_tensor = torch.tensor(y_test).long()\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=os.cpu_count())\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27f5576d-0efc-4893-bcc7-4586781726dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_dim, hidden_size=hidden_dim, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        if out.dim() >= 2:\n",
    "            out = out.squeeze().unsqueeze(1).squeeze(1)\n",
    "        #out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (hn, cn) = self.lstm(x)\n",
    "        if out.dim() >= 2:\n",
    "            out = out.squeeze().unsqueeze(1).squeeze(1)\n",
    "        #out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "class BiRNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(BiRNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_dim, hidden_size=hidden_dim, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        if out.dim() >= 2:\n",
    "            out = out.squeeze().unsqueeze(1).squeeze(1)\n",
    "        #out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (hn, cn) = self.lstm(x)\n",
    "        if out.dim() >= 2:\n",
    "            out = out.squeeze().unsqueeze(1).squeeze(1)\n",
    "        #out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b80e1101-0eaf-4ddb-951a-48797fd4b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, test_loader, device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(6): \n",
    "        for texts, labels in train_loader:\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(texts)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in test_loader:\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            outputs = model(texts)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Точность модели на тестовых данных: {accuracy}%')\n",
    "\n",
    "    print(\"Classification Report:\\n\", classification_report(all_labels, all_predictions))\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db235b9e-e10c-4ac0-a9bd-c5e6de622e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение и оценка RNN модели\n",
      "Точность модели на тестовых данных: 93.86378961564397%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89       319\n",
      "           1       0.96      0.99      0.98       390\n",
      "           2       0.91      0.97      0.94       398\n",
      "           3       0.96      0.93      0.94       376\n",
      "\n",
      "    accuracy                           0.94      1483\n",
      "   macro avg       0.94      0.93      0.94      1483\n",
      "weighted avg       0.94      0.94      0.94      1483\n",
      "\n",
      "RNN Точность: 93.86378961564397%\n",
      "\n",
      "Обучение и оценка LSTM модели\n",
      "Точность модели на тестовых данных: 92.91975724881996%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87       319\n",
      "           1       0.97      0.99      0.98       390\n",
      "           2       0.88      0.97      0.93       398\n",
      "           3       0.97      0.89      0.93       376\n",
      "\n",
      "    accuracy                           0.93      1483\n",
      "   macro avg       0.93      0.92      0.93      1483\n",
      "weighted avg       0.93      0.93      0.93      1483\n",
      "\n",
      "LSTM Точность: 92.91975724881996%\n",
      "\n",
      "Обучение и оценка BiRNN модели\n",
      "Точность модели на тестовых данных: 94.7403910991234%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91       319\n",
      "           1       0.96      0.99      0.98       390\n",
      "           2       0.93      0.97      0.95       398\n",
      "           3       0.96      0.92      0.94       376\n",
      "\n",
      "    accuracy                           0.95      1483\n",
      "   macro avg       0.95      0.94      0.95      1483\n",
      "weighted avg       0.95      0.95      0.95      1483\n",
      "\n",
      "BiRNN Точность: 94.7403910991234%\n",
      "\n",
      "Обучение и оценка BiLSTM модели\n",
      "Точность модели на тестовых данных: 94.13351314902225%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.90       319\n",
      "           1       0.97      0.99      0.98       390\n",
      "           2       0.91      0.97      0.94       398\n",
      "           3       0.97      0.92      0.94       376\n",
      "\n",
      "    accuracy                           0.94      1483\n",
      "   macro avg       0.94      0.94      0.94      1483\n",
      "weighted avg       0.94      0.94      0.94      1483\n",
      "\n",
      "BiLSTM Точность: 94.13351314902225%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]  \n",
    "hidden_dim = 128\n",
    "output_dim = len(set(y_train))  \n",
    "\n",
    "models = {\n",
    "    \"RNN\": RNNModel(input_dim, hidden_dim, output_dim).to(device),\n",
    "    \"LSTM\": LSTMModel(input_dim, hidden_dim, output_dim).to(device),\n",
    "    \"BiRNN\": BiRNNModel(input_dim, hidden_dim, output_dim).to(device),\n",
    "    \"BiLSTM\": BiLSTMModel(input_dim, hidden_dim, output_dim).to(device)\n",
    "}\n",
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Обучение и оценка {model_name} модели\")\n",
    "    accuracy = train_and_evaluate(model, train_loader, test_loader, device)\n",
    "    print(f\"{model_name} Точность: {accuracy}%\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c1448f-473a-418f-919a-02abd8680d46",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "\n",
    "методы глубокого обучения показали себя значительно лучше, также использованние двухнаправленных rnn и lstm \n",
    "\n",
    "дало чуть лучшие реузльтаты по сравнению с классическими rnn и lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145805ff-92c8-4cd6-bc6b-82776f8ba3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
